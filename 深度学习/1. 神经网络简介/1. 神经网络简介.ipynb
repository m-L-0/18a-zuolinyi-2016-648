{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络简介\n",
    "\n",
    "* 作者：王琪\n",
    "* 参考：《神经网络与机器学习》《深度学习》\n",
    "\n",
    "本章分为如下内容：\n",
    "\n",
    "1.1节 简述神经网络的来源与概念。\n",
    "\n",
    "1.2节 描述神经网络的基本结构。\n",
    "\n",
    "1.3节 简述神经网络的分类与常见的神经网络类别。\n",
    "\n",
    "1.4节 描述神经网络的学习方式与过程。\n",
    "\n",
    "1.5节 描述神经网络的性质与能力。\n",
    "\n",
    "1.6节 简述神经网络的应用场景。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 神经网络简介\n",
    "人脑是一个高度复杂的、非线性的和并行的计算机器，它的基本组成成分是神经元。人脑能够以极高的效率完成很多任务，例如模式识别，这与计算机在这些任务中的低效的表现形成鲜明的对比。受人脑计算的影响，从计算机诞生起就开始了使用计算机构造人工神经网络的相关研究。人工神经网络的定义有很多种，其中较为广泛使用的一种定义如下：\n",
    "\n",
    "**人工神经网络（Artificial neural network，ANN）**简称神经网络<sup>[1]</sup>，是由简单处理单元构成的大规模并行分布式处理器，天然地具有存储经验知识和使之可用的特性。\n",
    "\n",
    "神经网络在两个方面与大脑相似：\n",
    "1. 神经网络是通过学习过程从外界环境中获取知识的。\n",
    "2. 互连神经元的连接强度，即突触权值，用于存储获取的知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 网络基本结构\n",
    "神经网络中最基本的成分是神经元（neuron），即上述定义中的“简单处理单元”。在生物神经网络中，每个神经元与其它神经元相连，当它“兴奋”时，就会向相连的神经元发送化学物质，从而改变这些相连神经元内的电位；如果某神经元的电位超过了一个“阈值”（threshold），那么它就会被激活，即“兴奋”起来，向其它相连神经元发送化学物质。\n",
    "\n",
    "神经元有三个基本元素：\n",
    "\n",
    "1. 突触或连接链集（电流/信号搜集与变换）。\n",
    "2. 加法器（电流/信号积累）。\n",
    "3. 激活函数（非线性变换，将累加信号变换后输出，一般使用压制函数限制输出振幅）。\n",
    "\n",
    "1943年，McCulloch与Pitts将上述神经元要素抽象为下图所示的简单模型，这就是著名的“M-P神经元模型”。在这个模型中，神经元接收到来自 $n$ 个其它神经元传递过来的输入信号，这些输入信号通过带权重的连接对输入信号进行线性变换，神经元接收到的总输入与神经元的阈值进行比较，然后通过激活函数处理以产生神经元的输出。\n",
    "\n",
    "<img src='./images/M-P.png' width='800px' />\n",
    "\n",
    "M-P神经元将所有信号的输入看做是同时发生的，输入的信号在传导的过程中（与权重作用）进行了线性变换，输出时激活函数则选择阶跃函数模拟大脑神经元兴奋与抑制的两种状态，输出“1”代表神经元兴奋，输出“0”代表神经元抑制，激活函数如下图左图所示。阶跃函数具有不连续、不光滑等不太好的性质，因此实际中常常使用Sigmoid函数作为激活函数，其中常用的一种Sigmoid激活为Logistic激活函数如下图右图所示。\n",
    "\n",
    "<img src='./images/sgn_sigmoid.png' width='900px' />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把许多个神经元排成一排，可以组成一个单层前馈神经网络，这个网络的每一个神经元接收相同的数据作为输入，但每个神经元具有不同的连接权重、阈值，这样的一层网络可以输出与神经元一样多数量的值。单层前馈神经网络的输出也可以作为另一个单层神经网络的输入，以此相连在一起就组成了规模庞大的神经网络。\n",
    "<img src='./images/nn.png' width='500px' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很多神经网络都是分层结构的，神经网络中的层根据其所处位置，可以分为输入层、隐藏层、输出层。输入层即数据输入模型的层，有些时候不认为输入层是神经网络的一部分，但输入层确定了输出的规模与类型。输出层即模型输出结果的层，在回归任务中输出层负责输出一个或多个回归值，在分类任务中负责输出分类结果或类别置信度。除去输入层、输出层以外的层均为隐藏层，有些神经网络不包含隐藏层，例如单层前馈神经网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 网络类别\n",
    "神经网络模型、算法繁多。一般来说，我们可以区分三种基本不同的网络结构。\n",
    "* 单层前馈网络\n",
    "* 多层前馈网络\n",
    "* 递归网络\n",
    "\n",
    "其中单层前馈网络、多层前馈网络为前馈网络，递归网络为反馈网络。\n",
    "\n",
    "单层前馈网络即只有输入层（源节点）与输出层的网络，数据输入给计算节点（神经元）输出层。\n",
    "多层前馈网络有一层或多层隐藏层，即其计算节点为隐藏层、输出层单元（神经元）。引入隐藏层之后，网络成为了局部连接，由于额外的突触连接和额外的神经交互作用，也可以使网络在不十分严格的意义下获得一个全局关系（Churchland and Sejnowski，1992）。\n",
    "\n",
    "递归网络和前馈网络的区别在于它至少有一个反馈环。反馈环是指有些神经元的输出反馈到（来自输入方向的）其它或自身神经元的输入中，反馈网络也可以分为多层反馈网络与单层反馈网络。\n",
    "<img src='./images/selffeedback.png' width='300px' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上所述的三种基本结构的神经网络衍生出了各种网络模型。其中主要包括多层感知机、径向基函数（Radial Basis Function，RBF）网络、竞争学习网络、结构自适应网络、能量模型等。这其中最重要的是多层感知机的部分。\n",
    "\n",
    "* 感知机：由两层神经元组成的单层前馈网络，即M-P模型。\n",
    "* 多层感知机：由感知机组成的多层网络，后演变为深度学习的一部分。常见模型包括全连接神经网络、卷积神经网络、循环神经网络等。\n",
    "* RBF网络：是一种单隐层前馈网络，它的隐藏层使用径向基函数作为隐藏层神经元激活函数。Park和Sandberg在1991年证明，具有足够多隐藏层神经元的RBF网络能以任意精度逼近任意连续函数。\n",
    "* 竞争学习网络：是一种无监督神经网络，常见的模型包括ART网络、SOM网络等。\n",
    "* 结构自适应网络：一般网络模型通常假定网络结构是事先固定的，训练仅仅为了找到最佳参数。而结构自适应网络则将网络结构也当做学习目标之一。级联相关网络是一种常用的结构自适应网络。\n",
    "* 能量模型：一类网络将网络状态定义为“能量”，能量最小化时网络达到理想状态，被称为能量模型。Boltzmann机是一种基于能量的重要模型。\n",
    "\n",
    "随着计算设备的计算能力的提升以及神经网络的发展，神经网络模型的参数数量越来越多、模型越来越复杂，以深度学习为代表的复杂模型受到了人们的关注。典型的深度学习模型就是很深层的神经网络。显然，对神经网络模型，提高容量的一个简单办法是增加隐藏层神经元数目以及隐藏层的层数。现代的深度学习模型往往有几十到几百层深度的模型。\n",
    "\n",
    "深度学习模型包含了上述很多种模型。Hinton在2006年提出深度信念网络（多层受限Boltzmann机堆叠而成），并使用无监督预训练（unsupervised layer-wise training）与“微调”（fine-tuning）的方法达到有效训练深度模型的目的。后来随着计算机处理速度的快速提升，尤其是GPU的发展，“权值共享”（weight sharing）的卷积神经网络（Convolutional Neural Network，CNN）得以快速训练，并被大规模应用在图像处理领域。以往的机器学习任务，描述样本的特征通常需要由人类专家来设计，这被称为特征工程（feature engineering）。特征的好坏对模型泛化性能有至关重要的影响，人类专家设计出好特征也并非易事，卷积神经网络等模型的发展使得特征学习通过机器学习技术自身来产生好特征，使机器学习向“全自动数据分析”又进了一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 学习过程\n",
    "根据神经网络的功能对其学习过程进行如下分类：有教师学习和无教师学习。无教师学习又可分为无监督学习和强化学习两个子类。\n",
    "\n",
    "**有教师学习**：\n",
    "\n",
    "有教师学习也被称之为监督学习。即知识被表达为一系列的输入-输出样本，当我们将样本的输入（属性值）馈送入模型时，我们期望模型输出与样本输出（标记）一样的结果。当模型未训练时，模型的输出结果与预期差距大，此时可根据标记与模型输出之间的误差调整模型，即训练，最终使得模型向着我们期望的方向发展。当模型的表现足够优秀时，这时候就不在需要带有标记的数据集（教师）了。\n",
    "\n",
    "<img src='./images/learning_with_teacher.png' width='300px' />\n",
    "\n",
    "**无监督学习**：\n",
    "\n",
    "无监督学习是指没有教师指导（数据集标记），网络根据提供的距离度量来优化模型参数。就像其他机器学习模型中的聚类等任务，利用神经网络的无监督学习也能达到这些目标。\n",
    "\n",
    "<img src='./images/learning_without_teacher_0.png' width='260px' />\n",
    "\n",
    "**强化学习**：\n",
    "\n",
    "强化学习是指输入输出映射的学习是通过与环境的不断交互完成的，目标是使一个性能指标达到最小。强化学习不同于监督学习中样本-标记一一对应的关系，也不同于无监督学习。强化学习是在不同时刻可能面临不同环境，模型要在当前环境中完成一个操作，并接收环境的反馈，并不断循环直到产生一些特殊结果。由于这是一个序列过程，每一个时刻都会受到之前时刻操作的影响，所以当前的操作得到的反馈并不能决定模型最终收到的奖惩。\n",
    "\n",
    "<img src='./images/learning_without_teacher_1.png' width='280px' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5 神经网络的性质和能力\n",
    "1. 非线性（nonlinearity）：神经元可以是线性或非线性的，神经元相连组成的神经网络也可以是非线性的。\n",
    "\n",
    "2. 输入输出映射（input-output mapping）：即神经网络可以完成监督学习任务。\n",
    "\n",
    "3. 自适应性（adaptivity）：神经网络具有调整参数以适应环境变化的能力，即可以完成迁移学习。\n",
    "\n",
    "4. 证据响应（evidential response）：在分类任务中，神经网络能够提供决策的置信度信息，即可输出每个类别的概率。\n",
    "\n",
    "5. 上下文信息（contextual information）：神经网络中的每一个神经元都受其它（部分或全部）神经元的活动的影响。\n",
    "\n",
    "6. 容错性（fault tolerance）：神经网络中知识存储在每一个神经元的突触中，当某一个神经元或其连接损坏了，会降低神经网络的性能，但性能的降低是随神经元或其突触连接损坏的数量的增加而缓慢降低的。\n",
    "\n",
    "7. 超大规模集成实现（very-large-scale-intergrated implementability）：神经网络中的神经元可以并行运行以处理任务，这提供了一个以高度分层的方式来处理复杂行为的方法。\n",
    "\n",
    "8. 分析和设计的一致性：神经网络是由结构一致的神经元组成的通用信息处理器，这使得所有神经网络均具有相似的基础结构，并有能够使用相同的学习理论和学习算法的可能，同时也便于网络模块化设计、集成。\n",
    "\n",
    "9. 神经生物类比：神经网络的设计来源于人脑，同时神经网络也是能够用于解释生物现象的工具。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6 应用场景\n",
    "神经网络作为通用连续函数逼近器，理论上可以完成各种各样的任务，包括分类、回归、聚类、特征提取、降维、强化学习等。目前神经网络仍然远未达到我们理想的能与人脑处理任务相比的程度，只在部分任务中能够较好或优秀的工作。这主要包括以下几个方面：\n",
    "* 计算机视觉：自2012年AlexNet（卷积神经网络的一种实现）在大规模图像分类挑战赛中以绝对优势获胜，在计算机视觉的各个领域中都先后被神经网络占领。其应用领域最为广泛，例如自动驾驶汽车、城市安防、人脸识别、活体检测、肿瘤检测等。这其中在很多领域的应用已经达到超过人类平均水平的高度，例如在人脸识别的准确度上。\n",
    "* 自然语言处理：神经网络在自然语言处理中也是最常用的模型之一，包括语音语义识别、语音合成、翻译等都有很多应用。Google翻译正是使用了循环神经网络构建而成。\n",
    "* 智能博弈：围棋被誉为最复杂的游戏之一，神经网络应用在这一领域迅之后迅速打开了围棋世界的新大门，不仅占领了围棋的制高点，而且开发出了很多新的玩法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 练习\n",
    "\n",
    "1. 判断题\n",
    "    * [x] 互连神经元的连接强度，即突触权值，用于存储获取的知识。\n",
    "    * [ ] 阶跃函数输出 “0” 时表示神经元兴奋。\n",
    "    * [x] 循环神经网络是一种递归神经网络。\n",
    "    * [x] 强化学习是无教师学习。\n",
    "    * [ ] sgn函数是一种S型函数（Sigmoid函数）\n",
    "    * [ ] 训练好的神经网络去除一个神经元，整个神经网络就无法工作。\n",
    "    * [ ] 神经元的激活函数不能是线性函数。\n",
    "    * [x] 使用神经网络进行模式分类可以得到分类概率。\n",
    "    * [ ] M-P模型是一种单层前馈神经网络模型。\n",
    "    * [ ] 神经网络擅长处理计算机视觉任务，所以一切计算机视觉问题使用神经网络解决都是最好的。\n",
    "    \n",
    "2. 选择题\n",
    "    * 神经网络的基本要素包括（ ABD ）\n",
    "    \n",
    "    A. 突触 \n",
    "    \n",
    "    B. 加法器\n",
    "    \n",
    "    C. S型函数             \n",
    "    \n",
    "    D. 激活函数\n",
    "        \n",
    "    * 神经网络的性质与能力中不包括（  D  ）\n",
    "    \n",
    "    A. 容错性\n",
    "    \n",
    "    B. 超大规模集成实现\n",
    "    \n",
    "    C. 自适应性\n",
    "    \n",
    "    D. 确定性\n",
    "    \n",
    "    * 关于监督学习的理解错误的是（  AC ）\n",
    "    \n",
    "    A. 神经网络无法在没有标签的数据中学习知识。\n",
    "    \n",
    "    B. 监督学习也被称为有教师学习。\n",
    "    \n",
    "    C. 强化学习是一种监督学习。\n",
    "    \n",
    "    D. 监督学习是利用带有标签的数据训练模型使模型尽量输出与标记一致的结果。\n",
    "    \n",
    "    * 以下哪些模型不属于神经网络模型（  B  ）\n",
    "    \n",
    "    A. RBF网络\n",
    "    \n",
    "    B. SVM\n",
    "    \n",
    "    C. RNN\n",
    "    \n",
    "    D. SOM网络\n",
    "    \n",
    "3. 编写程序\n",
    "    * 在Python环境下使用Numpy编写Sgn、Logistic激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sgn(x):\n",
    "    if x >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def logistic(x):\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[  1  ]: 神经网络的定义来自 Aleksander and Morton（1990）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
