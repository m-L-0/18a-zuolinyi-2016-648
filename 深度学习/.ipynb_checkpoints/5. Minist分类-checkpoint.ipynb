{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 下载MNIST数据集并生成DataSet对象\n",
    "# 使用OneHot编码处理标记\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集图片矩阵，代表55000张图片，每张图片为一个向量，其长度为784\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集标记矩阵，代表55000张图片的标记，每张图片为一个10维的独热编码向量\n",
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x249800116a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化训练集中的图片\n",
    "plt.imshow(Image.fromarray(mnist.train.images[0].reshape(28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step     0, loss 13.5996, acc 0.1402\n",
      "step   500, loss 10.7579, acc 0.2552\n",
      "step  1000, loss 7.5571, acc 0.3935\n",
      "step  1500, loss 8.8122, acc 0.4794\n",
      "step  2000, loss 7.2045, acc 0.5208\n",
      "step  2500, loss 5.2815, acc 0.5498\n",
      "step  3000, loss 8.9044, acc 0.5643\n",
      "step  3500, loss 5.1427, acc 0.5742\n",
      "step  4000, loss 4.2028, acc 0.5766\n",
      "step  4500, loss 6.6785, acc 0.5897\n",
      "step  5000, loss 5.4818, acc 0.5936\n",
      "step  5500, loss 4.0768, acc 0.5999\n",
      "step  6000, loss 8.0590, acc 0.6042\n",
      "step  6500, loss 5.0369, acc 0.6053\n",
      "step  7000, loss 8.0581, acc 0.6082\n",
      "step  7500, loss 5.7684, acc 0.6109\n",
      "step  8000, loss 5.5406, acc 0.6173\n",
      "step  8500, loss 4.5361, acc 0.6348\n",
      "step  9000, loss 4.2210, acc 0.6664\n",
      "step  9500, loss 2.7183, acc 0.6866\n",
      "step 10000, loss 5.8950, acc 0.6947\n",
      "step 10500, loss 2.5843, acc 0.7038\n",
      "step 11000, loss 4.0299, acc 0.7030\n",
      "step 11500, loss 1.6042, acc 0.7086\n",
      "step 12000, loss 4.5596, acc 0.7093\n",
      "step 12500, loss 3.5258, acc 0.7099\n",
      "step 13000, loss 3.5259, acc 0.7126\n",
      "step 13500, loss 4.5332, acc 0.7131\n",
      "step 14000, loss 5.7670, acc 0.7160\n",
      "step 14500, loss 6.0657, acc 0.7158\n",
      "step 15000, loss 3.5638, acc 0.7178\n",
      "step 15500, loss 4.4881, acc 0.7181\n",
      "step 16000, loss 3.0222, acc 0.7213\n",
      "step 16500, loss 4.0254, acc 0.7199\n",
      "step 17000, loss 4.5332, acc 0.7241\n",
      "step 17500, loss 6.0922, acc 0.7223\n",
      "step 18000, loss 5.8463, acc 0.7260\n",
      "step 18500, loss 4.5332, acc 0.7215\n",
      "step 19000, loss 2.5370, acc 0.7290\n",
      "step 19500, loss 5.0369, acc 0.7266\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    # 输入、标记占位符\n",
    "    inputs = tf.placeholder(shape=[None, 784], dtype=tf.float32)\n",
    "    labels = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    # 创建128个隐藏层神经元参数\n",
    "    hidden_weight = tf.Variable(tf.random_normal([784, 128]), name='hidden_weight')\n",
    "    hidden_bias = tf.Variable(tf.zeros([128, ]), name='hidden_bias')\n",
    "    # 隐藏层前向传播\n",
    "    hidden_output = tf.nn.relu(tf.matmul(inputs, hidden_weight) + hidden_bias)\n",
    "    \n",
    "    \n",
    "    # 创建输出层10个神经元参数\n",
    "    output_weight = tf.Variable(tf.random_normal([128, 10], name='output_weight'))\n",
    "    output_bias = tf.Variable(tf.zeros([10, ]), name='output_bias')\n",
    "    # 输出层前向传播\n",
    "    logits = tf.matmul(hidden_output, output_weight) + output_bias\n",
    "    output = tf.nn.softmax(logits)\n",
    "    \n",
    "    \n",
    "    # 代价函数\n",
    "    loss = tf.reduce_mean(-1 * tf.reduce_sum(\n",
    "        labels * tf.log(output + 1e-7),\n",
    "        axis=1))\n",
    "    \n",
    "    \n",
    "    # 正确率\n",
    "    acc = tf.reduce_mean(\n",
    "        tf.cast(tf.equal(tf.argmax(labels, axis=1), tf.argmax(output, axis=1)),\n",
    "                tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # 定义梯度下降法优化器\n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "    train_op = optim.minimize(loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 训练模型\n",
    "    for step in range(20000):\n",
    "        batch_images, batch_labels = mnist.train.next_batch(32)\n",
    "        res_loss, _ = sess.run([loss, train_op], feed_dict={\n",
    "            inputs: batch_images,\n",
    "            labels: batch_labels\n",
    "        })\n",
    "        \n",
    "        # 输出代价并验证模型\n",
    "        if step % 500 == 0:\n",
    "            accs = []\n",
    "            for test_step in range(10000 // 32):\n",
    "                batch_images, batch_labels = mnist.test.next_batch(32)\n",
    "                res_acc = sess.run(acc, feed_dict={\n",
    "                    inputs: batch_images,\n",
    "                    labels: batch_labels\n",
    "                })\n",
    "                accs.append(res_acc)\n",
    "            accs = np.mean(accs)\n",
    "            print('step %5d, loss %2.4f, acc %.4f' % (step, res_loss, accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
